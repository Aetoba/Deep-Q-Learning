import numpy as np

from utils.process_frame import phi
from utils.run_network import max_action_preds
from utils.choose_action import choose_action

class Exploit:
    """
    Runs with epsilon = 0.05 to estimate performance.
    """
    def __init__(self, sess, Q, env, frame_stack_size, max_steps):
        self.sess = sess
        self.Q = Q
        self.env = env
        self.n_actions = env.action_space.n
        self.frame_stack_size = frame_stack_size
        self.max_steps = max_steps

    def run_exploit(self):
        n_screen = self.env.reset()
        state, stack_state = phi(n_screen, self.frame_stack_size, new_episode=True)

        step = 0
        done = False
        total_rew = 0
        while step < self.max_steps and not done:
            action, p_val = choose_action(stack_state, self.Q, self.sess, 0.05, self.n_actions)
            n_screen, reward, done, _ = self.env.step(np.argmax(action))
            total_rew += reward
            state, stack_state = phi(n_screen, self.frame_stack_size, curr_state=state)
            step += 1

        return total_rew, step
